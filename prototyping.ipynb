{
 "cells": [
  {
   "source": [
    "Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from os import walk\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib"
   ]
  },
  {
   "source": [
    "Finding files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Analyzing 1 file:\n\tcomp220.txt\n"
     ]
    }
   ],
   "source": [
    "# Looking for the files in the /data folder\n",
    "mypath = os.path.abspath(os.getcwd()) + \"/data\"\n",
    "ext = \"txt\"\n",
    "files = []\n",
    "for (dirpath, dirnames, filenames) in walk(mypath):\n",
    "    for file in filenames:\n",
    "        if file.split(\".\")[1] == ext:  # Only files with the right extension\n",
    "            files.append(file)\n",
    "    break\n",
    "if not files:  # if files is empty\n",
    "    raise Exception(\"Warning there are no files, check the path!\")\n",
    "    quit()  # no need to proceed\n",
    "\n",
    "s = \"\" if len(files) == 1 else \"s\"\n",
    "print(f\"Analyzing {len(files)} file{s}:\")\n",
    "t = [print(\"\\t\" + file) for file in files]"
   ]
  },
  {
   "source": [
    "Generating list of links from techleap"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "\n",
    "for file in files:\n",
    "\tfile = open(f\"Data/{file}\", \"r\").read()\n",
    "\tfor i in [m.start() for m in re.finditer('href', file)]:\n",
    "\t\tclosingcommas = file[i : i+50].find(\">\")\n",
    "\t\tlink = file[i+6 : i+closingcommas-1]\n",
    "\t\tlinks.append(link)"
   ]
  },
  {
   "source": [
    "Generating list of companies links"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "error:\t<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1108)>\n"
     ]
    }
   ],
   "source": [
    "complinks = []\n",
    "nocomplinks = []\n",
    "for link in links:\n",
    "\turl = \"https://finder.techleap.nl\" + link\n",
    "\ttry:\n",
    "\t\treq = urllib.request.Request(url, headers={'User-Agent' : \"Magic Browser\"}) \n",
    "\t\tpage = urlopen(req)\n",
    "\texcept Exception as e:\n",
    "\t\tprint(\"error:\\t\" + str(e))\n",
    "\t\tbreak\n",
    "\n",
    "\tsoup = BeautifulSoup(page, 'html.parser')\n",
    "\t\n",
    "\tlink = link.replace(\"_\", \"\")\n",
    "\tsave = True\n",
    "\thaslink = False\n",
    "\tfor href in soup.find_all('a'):\n",
    "\t\ttemplink = href.get('href')\n",
    "\t\tif link.split(\"/\")[2] in templink and \"http\" in templink:\n",
    "\t\t\tfor domain in [\"facebook\", \"google\", \"linkedin\", \"twitter\", \"apple\"]:\n",
    "\t\t\t\tif domain in templink:\n",
    "\t\t\t\t\tsave = False\n",
    "\t\t\tif save:\n",
    "\t\t\t\tprint(link, \"\\t\", templink)\n",
    "\t\t\t\tcomplinks.append(templink)\n",
    "\t\t\t\thaslink = True\n",
    "\tif not haslink:\n",
    "\t\tnocomplinks.append(link) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "117 didn't have a link out of 117 companies\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(links) - len(complinks)} didn't have a link out of {len(links)} companies\")"
   ]
  },
  {
   "source": [
    "Searching for emails"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "http://www.mx3d.com \t info@mx3d.com\n",
      "http://www.mx3d.com \t press@mx3d.com\n",
      "http://www.shypple.com \t info@shypple.com\n",
      "http://www.swipeguide.com \t hello@swipeguide.com\n",
      "http://clairify.io \t felix@clairify.io\n",
      "http://clairify.io \t tibor@clairify.io\n",
      "http://clairify.io \t wim@clairify.io\n",
      "http://clairify.io \t info@clairify.io\n",
      "https://www.katanox.com \t hello@katanox.com\n",
      "http://baqme.com \t support@baqme.com\n",
      " * * * Error opening https://www.denoize.com\n",
      " * * * <urlopen error [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1091)>\n",
      "https://www.targedbiopharmaceuticals.com \t info@targedbio.com\n",
      "http://getrodeo.io \t info@getrodeo.io\n",
      "http://www.flego.nl \t mathijs@flego.nl\n",
      "http://www.flego.nl \t info@flego.nl\n",
      "https://enzyre.com \t investors@enzyre.com\n",
      "https://enzyre.com \t info@enzyre.com\n",
      "http://zielwear.com \t email@address.com\n",
      "http://zielwear.com \t sayhi@zielwear.com\n",
      "https://www.leadinfo.com \t hello@leadinfo.com\n"
     ]
    }
   ],
   "source": [
    "compmails = {}\n",
    "for link in complinks:\n",
    "    try:\n",
    "        req = urllib.request.Request(link, headers={'User-Agent' : \"Magic Browser\"}) \n",
    "        con = urlopen(req)\n",
    "    except Exception as e:\n",
    "        print(f\" * * * Error opening {link}\")\n",
    "        print(\" * * * \" + str(e))\n",
    "\n",
    "    s = con.read().decode(\"utf-8\")\n",
    "    emails = re.findall(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,4}\", s)\n",
    "    newemails = list(set(emails))\n",
    "    compmails[link] = []\n",
    "    for mail in newemails:\n",
    "        if mail.split(\".\")[-1] == link.split(\".\")[-1] and \"%20\" not in mail:\n",
    "            compmails[link].append(mail)\n",
    "            print(link, \"\\t\", mail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "http://www.mx3d.com\n\tinfo@mx3d.com\n\tpress@mx3d.com\nhttp://www.shypple.com\n\tinfo@shypple.com\nhttp://www.swipeguide.com\n\thello@swipeguide.com\nhttp://inuka.io\nhttp://24sessions.com\nhttps://www.bringly.nl/\nhttp://www.getroadmap.com/\nhttp://clairify.io\n\tfelix@clairify.io\n\ttibor@clairify.io\n\twim@clairify.io\n\tinfo@clairify.io\nhttps://www.lightyear.one/\nhttp://www.fangage.com/\nhttps://www.sonicbee.nl/en/\nhttps://foundahealth.com/\nhttp://postoplan.app\nhttps://www.veylinx.com/\nhttps://www.katanox.com\n\thello@katanox.com\nhttps://felyx.com/\nhttp://baqme.com\n\tsupport@baqme.com\nhttp://tripactions.com\nhttps://www.denoize.com\nhttps://www.dockrmobility.nl/nl/\nhttps://axoniq.io/\nhttps://packaly.com/\nhttp://www.omnigen.nl\nhttps://www.confocal.nl/\nhttps://www.cortexter.com\nhttps://www.targedbiopharmaceuticals.com\n\tinfo@targedbio.com\nhttps://satelligence.com/\nhttp://getrodeo.io\n\tinfo@getrodeo.io\nhttps://mriguidance.com/\nhttps://viteezy.nl\nhttps://weareeves.com/\nhttps://syncvr.tech\nhttps://www.medvice.io/\nhttps://cloudcuddle.com/\nhttps://codesandbox.io\nhttps://designbro.com\nhttps://www.zivver.com\nhttps://www.verdify.tech\nhttp://www.gobiond.com/\nhttp://www.circularise.com\nhttps://www.attendi.nl/\nhttps://www.plotwise.com/\nhttps://worksuite.nl/\nhttps://www.orderchamp.com\nhttps://www.chaincargo.eu/\nhttps://www.blockdata.tech\nhttp://www.scoozy.nl/\nhttps://www.overstory.ai/\nhttp://www.flego.nl\n\tmathijs@flego.nl\n\tinfo@flego.nl\nhttps://pharmaoffer.com/\nhttps://www.siilo.com/\nhttps://goasobo.com/\nhttps://enzyre.com\n\tinvestors@enzyre.com\n\tinfo@enzyre.com\nhttp://zielwear.com\n\temail@address.com\n\tsayhi@zielwear.com\nhttp://www.varmx.com/\nhttp://citryll.com/\nhttps://www.oncochain.com/\nhttp://corporis-medical.com/\nhttps://www.leadinfo.com\n\thello@leadinfo.com\nhttps://www.theydo.io\nhttps://wordproof.io/\n"
     ]
    }
   ],
   "source": [
    "for i in compmails:\n",
    "    print(i)\n",
    "    [print(\"\\t\" + x) for x in compmails[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/companies/qlayersbv\n/companies/kaminarimedicalbv\n/companies/carttech\n/companies/theselectionlabbv\n/companies/invisiblefood\n/companies/getstreamio\n/companies/semioticlabs\n/companies/spikemobility\n/companies/ellipsisdrive\n/companies/emagy\n/companies/lipocoatbv\n/companies/stilbv\n/companies/orangegames\n/companies/stack2\n/companies/evbiotech\n/companies/asthmawarebv\n/companies/stepmobility\n/companies/cooperapp\n/companies/praxasensebv\n/companies/ecgexcellence\n/companies/trunkrsbv\n/companies/amflow\n/companies/tretbox\n/companies/salviabioelectronics\n/companies/neogenetherapeutics\n/companies/semitechnologies\n/companies/eindhovenmedicalrobotics\n/companies/skyned\n/companies/hyzonmotorseurope\n/companies/skiniveholdingbv\n/companies/slamorthobv\n/companies/akthelhealthcare\n/companies/vicotherapeutics\n/companies/synthesisinstitute\n/companies/inocellsbv\n/companies/inicarehealthtechnology\n/companies/asyliadiagnostics\n/companies/hemoclearbv\n/companies/unilife\n/companies/actpluzbv\n/companies/surgeon\n"
     ]
    }
   ],
   "source": [
    "for i in nocomplinks:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'compmails' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b014b0d17253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Printing mails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompmails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompmails\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compmails' is not defined"
     ]
    }
   ],
   "source": [
    "# Printing mails\n",
    "for i in compmails():\n",
    "\tprint(i)\n",
    "\t[print(\"\\t\" + x) for x in compmails[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python383jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.8.3 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}